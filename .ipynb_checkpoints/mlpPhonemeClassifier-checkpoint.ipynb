{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary files\n",
    "trainFile = \"/home/lab/Kevin/PhonemeClassification/Features/Non-Causal Anechoic/mfcc13_train.txt\"\n",
    "devFile = \"/home/lab/Kevin/PhonemeClassification/Features/Non-Causal Anechoic/mfcc13_dev.txt\"\n",
    "testFile = \"/home/lab/Kevin/PhonemeClassification/Features/Non-Causal Anechoic/mfcc13_test.txt\"\n",
    "#trainFile = \"mfcc13_train_dr1.txt\"\n",
    "#testFile = \"mfcc13_test_dr1.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in files\n",
    "def readFeatFile(filename):\n",
    "    \"\"\" This function reads features and labels from a text file.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): name of text file containing features and labels\n",
    "        \n",
    "    Returns:\n",
    "        X (np.array): matrix of features\n",
    "        y (list): list of phoneme labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read in features and labels as a string\n",
    "    file_obj = open(filename,\"r\")\n",
    "    x = file_obj.readlines()\n",
    "    file_obj.close()\n",
    "    \n",
    "    # Initialize lists to hold features and phone labels\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # Iterate through lines and extract features and labels\n",
    "    for i in range(0,len(x)):\n",
    "        # Single line in text file representing a single frame\n",
    "        singleFrame = x[i].split()\n",
    "        \n",
    "        # Phone labels expressed as strings\n",
    "        y.append(singleFrame[-1])\n",
    "        \n",
    "        # Convert features from strings to numbers\n",
    "        singleFrameFeat = []\n",
    "        for j in range(0,len(singleFrame)-1):\n",
    "            singleFrameFeat.append(float(singleFrame[j]))\n",
    "        \n",
    "        # Dynamically append converted features to growing list\n",
    "        X.append(singleFrameFeat)\n",
    "    \n",
    "    X = np.array(X, dtype='float32')\n",
    "    X = X[:,78:104] # just MFCCs and deltas of the current frame\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in features and labels for both the training and testing sets\n",
    "xTrain, yTrain = readFeatFile(trainFile)\n",
    "xDev, yDev = readFeatFile(devFile)\n",
    "xTest, yTest = readFeatFile(testFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine dev and test sets into one\n",
    "xTest = np.vstack((xTest,xDev))\n",
    "yTest.extend(yDev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training set into training and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xTrain, xValid, yTrain, yValid = train_test_split(xTrain, yTrain, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features according to training data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(xTrain)\n",
    "xTrain = scaler.transform(xTrain)\n",
    "xValid = scaler.transform(xValid)\n",
    "xTest = scaler.transform(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(yTest[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform phone labels to integers since this is required by PyTorch\n",
    "le = preprocessing.LabelEncoder()\n",
    "yTrain = (le.fit_transform(yTrain)).astype('long')\n",
    "yValid = le.transform(yValid).astype('long')\n",
    "yTest = le.transform(yTest).astype('long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(num_features, 250) # Will need to change the input depending on # of features\n",
    "        self.fc2 = nn.Linear(250, num_classes) # Will need to change the output depending on # of classes\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "def initializeWeights(m):\n",
    "    \"\"\" Initialize weights from Uniform(-0.1,0.1) distribution\n",
    "    as was done in Graves and Schmidhuber, 2005\n",
    "    \n",
    "    Args:\n",
    "        m\n",
    "        \n",
    "    Returns:\n",
    "        none\n",
    "    \"\"\"\n",
    "    if type(nn) == 'Linear':\n",
    "        torch.nn.init.uniform_(m.weight.data,a=-0.1,b=0.1)\n",
    "        torch.nn.init.uniform_(m.bias.data,a=-0.1,b=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(np.shape(xTrain)[1],len(np.unique(yTrain)))\n",
    "net.apply(initializeWeights)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays into tensors\n",
    "xTrain = torch.from_numpy(xTrain)\n",
    "xTest = torch.from_numpy(xTest)\n",
    "xValid = torch.from_numpy(xValid)\n",
    "yValid = torch.from_numpy(yValid)\n",
    "yTrain = torch.from_numpy(yTrain)\n",
    "yTest = torch.from_numpy(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainSet = torch.utils.data.DataLoader([xTest,yTest],batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "num_epochs = 1000\n",
    "learn_rate = 1e-5\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=learn_rate)\n",
    "\n",
    "# Put data onto device\n",
    "xTrain, yTrain = xTrain.to(device), yTrain.to(device)\n",
    "xValid, yValid = xValid.to(device), yValid.to(device)\n",
    "\n",
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    # Get outputs\n",
    "    train_outputs = net(xTrain)\n",
    "    valid_outputs = net(xValid)\n",
    "\n",
    "    # Calculate loss for training and validation sets\n",
    "    train_loss = F.cross_entropy(train_outputs, yTrain)\n",
    "    valid_loss = F.cross_entropy(valid_outputs, yValid)\n",
    "\n",
    "    # Backpropagate wrt training loss and optimize\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 99:\n",
    "        print(\"Epoch: {}, Training Loss: {}, Validation Loss: {}\".\n",
    "                format(epoch+1, round(float(train_loss),3), round(float(valid_loss),3)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "# Move testing data to device\n",
    "xTest = xTest.to(device)\n",
    "\n",
    "outputs = net(xTest)\n",
    "yPred = torch.argmax(outputs, dim=1)\n",
    "\n",
    "# Move outputs and predictions back to CPU\n",
    "outputs = outputs.to('cpu')\n",
    "yPred = yPred.to('cpu')\n",
    "\n",
    "# Accuracy\n",
    "accuracy = float(torch.sum(yTest==yPred))/float(len(yTest))\n",
    "print(\"Accuracy: \", round(accuracy,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
