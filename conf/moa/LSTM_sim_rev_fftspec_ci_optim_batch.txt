[Architecture]
model_type = LSTM
bidirectional = False
num_hidden = 123
num_classes = 7

[Training]
batch_size = 16
chunk_len = 1000
num_epochs = 250
learning_rate = 1e-3
momentum = 0.9
label_type = moa
optimizer = adam

[Datasets]
training = data/train_librispeech_sim_rev/log_fft.txt
development = data/dev_librispeech_sim_rev/log_fft.txt

[Features]
feature_type = fftspec_ci
num_coeffs = 65
use_energy = False
deltas = False
deltaDeltas = False
