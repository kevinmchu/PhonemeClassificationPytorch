{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Features\n",
    "from feature_extraction import fit_normalizer\n",
    "from feature_extraction import read_feat_file\n",
    "#from feature_extraction import readFeatsAndLabsSingleWavFile\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from validation import read_feat_list\n",
    "from validation import train_val_split\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Models\n",
    "from net import Net\n",
    "from net import initialize_weights\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from phone_mapping import phoneme2moa\n",
    "from confusion_matrix import sort_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary files\n",
    "train_feat_file = \"features/mfcc13_train.txt\"\n",
    "train_feat_list = \"data/train.txt\"\n",
    "dev_feat_list = \"data/dev.txt\"\n",
    "test_feat_list = \"data/test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = read_feat_list(train_feat_list)\n",
    "dev_list = read_feat_list(dev_feat_list)\n",
    "test_list = read_feat_list(test_feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine dev and test sets into one\n",
    "test_list = test_list + dev_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split list of utterances into training and validation sets\n",
    "valid_list, train_list = train_val_split(train_list, 184)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features according to training data\n",
    "scaler = fit_normalizer(train_feat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [\"sil\",\n",
    "         \"b\",\"d\",\"g\",\"p\",\"t\",\"k\",\"dx\",\n",
    "         \"ch\",\"jh\",\n",
    "         \"s\",\"sh\",\"z\",\"zh\",\"f\",\"v\",\"th\",\"dh\",\"hh\",\n",
    "         \"m\",\"n\",\"ng\",\n",
    "         \"l\",\"r\",\"w\",\"y\",\n",
    "         \"aa\",\"ae\",\"ah\",\"ao\",\"aw\",\"ay\",\"eh\",\"er\",\"ey\",\"ih\",\"iy\",\"ow\",\"oy\",\"uh\",\"uw\"]\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=26, out_features=250, bias=True)\n",
       "  (fc2): Linear(in_features=250, out_features=41, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the network\n",
    "net = Net(26,41) # should calculate number of features and classes above\n",
    "\n",
    "# Initialize weights\n",
    "net.apply(initialize_weights)\n",
    "\n",
    "# Send network to GPU (if applicable)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_and_test import train\n",
    "from train_and_test import validate\n",
    "from train_and_test import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 3.518, Validation Loss 3.37\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d36af06de6d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Kevin/PhonemeClassificationPytorch/train_and_test.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, optimizer, le, file_list)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Extract features and labels for current file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_feat_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Normalize features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Kevin/PhonemeClassificationPytorch/feature_extraction.py\u001b[0m in \u001b[0;36mread_feat_file\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# Read in features and labels as a string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mfile_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mfile_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/_bootlocale.py\u001b[0m in \u001b[0;36mgetpreferredencoding\u001b[0;34m(do_setlocale)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_setlocale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_setlocale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdo_setlocale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_locale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnl_langinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_locale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCODESET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "num_epochs = 10\n",
    "learn_rate = 1e-5\n",
    "m = 0.9\n",
    "\n",
    "# Stochastic gradient descent with user-defined learning rate and momentum\n",
    "optimizer = optim.SGD(net.parameters(), lr=learn_rate, momentum=m)\n",
    "\n",
    "# Preallocate vectors to hold loss\n",
    "train_loss = np.zeros((num_epochs, 1))\n",
    "valid_loss = np.zeros((num_epochs, 1))\n",
    "\n",
    "# Set to training mode\n",
    "net.train()\n",
    "\n",
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    # Randomly shuffle list of training and validation files\n",
    "    random.shuffle(train_list)\n",
    "    random.shuffle(valid_list)\n",
    "    \n",
    "    # Training\n",
    "    train_loss[epoch] = train(net, optimizer, le, train_list)\n",
    "    \n",
    "    # Validation\n",
    "    valid_loss[epoch] = validate(net, le, valid_list)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch: {}, Training Loss: {}, Validation Loss {}\".\n",
    "              format(epoch+1, round(float(train_loss[epoch]),3), round(float(valid_loss[epoch]),3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Curves\n",
    "epochs = np.arange(0, epoch, 1)\n",
    "plt.plot(epochs, train_loss[0:epoch], 'b')\n",
    "plt.plot(epochs, valid_loss[0:epoch], 'r--')\n",
    "plt.title(\"Cross Entropy Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Training\", \"Validation\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "summary = test(net, le, scaler, test_list)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(np.concatenate(summary['y_true']), np.concatenate(summary['y_pred']))\n",
    "    \n",
    "# Calculate accuracy\n",
    "accuracy = np.sum(np.diagonal(cm))/float(np.sum(cm))\n",
    "    \n",
    "# Normalize confusion matrix\n",
    "cm = cm.astype('float')/np.tile(np.reshape(np.sum(cm,axis=1),(len(cm),1)),(1,len(cm)))\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "classes_int = np.arange(0,len(labels),1)\n",
    "classes_str = le.inverse_transform(classes_int)\n",
    "\n",
    "# Sort confusion matrix in specific order\n",
    "cm = sort_classes(cm, classes_str, labels)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(cm)\n",
    "plt.title(\"Percent Correct = {}%\".format(round(accuracy*100,1)))\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.xticks(classes_int, labels)\n",
    "plt.yticks(classes_int, labels)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert phonemes to manner of articulation\n",
    "moa_true = phoneme2moa(le.inverse_transform(np.concatenate(summary['y_true'])))\n",
    "moa_pred = phoneme2moa(le.inverse_transform(np.concatenate(summary['y_pred'])))\n",
    "\n",
    "# Convert manner of articulation string labels into integer labels\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "moa_true = le2.fit_transform(moa_true)\n",
    "moa_pred = le2.transform(moa_pred)\n",
    "\n",
    "# Calculate accuracy for manner of articulation\n",
    "moa_accuracy = np.sum(np.array(moa_true)==np.array(moa_pred))/float(len(moa_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "moa_int = np.arange(0,len(np.unique(moa_true)),1)\n",
    "moa_str = le2.inverse_transform(moa_int)\n",
    "\n",
    "cm2 = confusion_matrix(moa_true, moa_pred)\n",
    "\n",
    "# Sort in specific order\n",
    "sort_order = [\"silence\",\"stop\",\"affricate\",\"fricative\",\"nasal\",\"semivowel\",\"vowel\"]\n",
    "cm2 = sort_classes(cm2, moa_str, sort_order)\n",
    "\n",
    "cm2 = cm2.astype('float')/np.tile(np.reshape(np.sum(cm2,axis=1),(len(cm2),1)),(1,len(cm2)))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(cm2)\n",
    "plt.title(\"Percent Correct = {}%\".format(round(moa_accuracy*100,1)))\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.xticks(moa_int, sort_order)\n",
    "plt.yticks(moa_int, sort_order)\n",
    "plt.colorbar()\n",
    "plt.clim(0, 1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
